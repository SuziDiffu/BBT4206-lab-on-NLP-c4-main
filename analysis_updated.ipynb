{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97abdd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "# nlp_course_eval_analysis.py\n",
    "# Full pipeline: load -> clean -> topic modelling -> sentiment -> gradio demo script export\n",
    "\n",
    "# Recommended environment (requirements.txt)\n",
    "# pandas\n",
    "# scikit-learn\n",
    "# joblib\n",
    "# nltk\n",
    "# gensim\n",
    "# pyldavis\n",
    "# gradio\n",
    "# umap-learn\n",
    "# hdbscan\n",
    "# bertopic (optional, for embeddings-based topics)\n",
    "# transformers (optional, for transformer sentiment)\n",
    "# vaderSentiment\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import joblib\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Optional: for an embeddings based topic model (BERTopic)\n",
    "# from bertopic import BERTopic\n",
    "\n",
    "# For VADER sentiment (rule-based)\n",
    "import nltk\n",
    "try:\n",
    "    from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "except:\n",
    "    nltk.download('vader_lexicon')\n",
    "    from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63409415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text columns: ['f_1_In_your_opinion_which_topics_(if_any)_should_be_added_to_the_Business_Intelligence_I_and_II_curriculum', 'f_2_In_your_opinion_which_topics_(if_any)_should_be_removed_from_the_Business_Intelligence_I_and_II_curriculum', 'f_3_Write_at_least_two_things_you_liked_about_the_teaching_and_learning_in_this_course', 'f_4_Write_at_least_one_recommendation_to_improve_the_teaching_and_learning_in_this_course_(for_future_classes)']\n",
      "Responses: 129\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# -------------- Step 1: Load data ----------------\n",
    "url = \"https://raw.githubusercontent.com/course-files/NaturalLanguageProcessing/refs/heads/main/data/202511-ft_bi1_bi2_course_evaluation.csv\"\n",
    "df = pd.read_csv(url, encoding='utf-8', low_memory=False)\n",
    "\n",
    "# Identify free-text columns (adjust if names are different)\n",
    "text_cols = [c for c in df.columns if c.startswith('f_')]\n",
    "print(\"Text columns:\", text_cols)\n",
    "\n",
    "# Combine free-text columns into one 'response' column per-student\n",
    "df['response'] = df[text_cols].fillna('').astype(str).apply(lambda row: ' '.join(row.values), axis=1)\n",
    "\n",
    "# Drop empty responses\n",
    "df = df[df['response'].str.strip().str.len() > 5].copy()\n",
    "print(\"Responses:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4635630",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -------------- Step 2: Clean text ----------------\n",
    "import string\n",
    "def clean_text(s):\n",
    "    s = str(s).lower()\n",
    "    s = re.sub(r\"http\\S+\",\" \", s)\n",
    "    s = re.sub(r\"[^a-z0-9\\s]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "df['text'] = df['response'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29357092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 : practical, data, bi, business, real, lab, theory, like, tools, real world, topics, world\n",
      "Topic 1 : labs, time, content, unit, topics, work, lab, opinion, quizzes, think, time series, series\n",
      "Topic 2 : slides, liked, labs, lecture, content, number, learning, better, work, notes, number slides, bi\n",
      "Topic 3 : data, practical, labs, unit, tools, matter, enjoyed, detailed, world, real world, engaging, opinion\n",
      "Topic 4 : lab, assignments, content, work, group, practical, okay, like, topics, notes, module, labs\n",
      "Topic 5 : topics, labs, think, end, topic, practical, understanding, real, business, class, course, understand\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# -------------- Step 3: Topic modelling (LDA) -------------\n",
    "# Vectorize (unigrams + bigrams)\n",
    "vectorizer = CountVectorizer(max_df=0.6, min_df=2, stop_words='english', ngram_range=(1,2))\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "n_topics = 6  # start with 6; tune by coherence / interpretability\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, random_state=42, max_iter=20)\n",
    "lda.fit(X)\n",
    "\n",
    "# Helper: get top words\n",
    "def top_words(model, feature_names, n=10):\n",
    "    topics = []\n",
    "    for i, comp in enumerate(model.components_):\n",
    "        top = comp.argsort()[:-n-1:-1]\n",
    "        topics.append([feature_names[j] for j in top])\n",
    "    return topics\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "topics = top_words(lda, feature_names, n=12)\n",
    "for i,t in enumerate(topics):\n",
    "    print(\"Topic\", i, \":\", ', '.join(t))\n",
    "\n",
    "# Assign dominant topic to each doc\n",
    "doc_topic_dist = lda.transform(X)\n",
    "df['dominant_topic'] = doc_topic_dist.argmax(axis=1)\n",
    "df['topic_prob'] = doc_topic_dist.max(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8e5b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------- Step 4: Sentiment per-response -------------\n",
    "# Use VADER (rule-based) for short student comments\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def vader_sentiment(text):\n",
    "    s = sia.polarity_scores(text)['compound']\n",
    "    return s\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "def vader_sentiment(text):\n",
    "    s = sia.polarity_scores(text)['compound']\n",
    "    if s >= 0.05:\n",
    "        return 'positive', s\n",
    "    elif s <= -0.05:\n",
    "        return 'negative', s\n",
    "    else:\n",
    "        return 'neutral', s\n",
    "\n",
    "df[['vader_sentiment','vader_score']] = df['text'].apply(lambda t: pd.Series(vader_sentiment(t)))\n",
    "\n",
    "# Optional fallback / check: small lexicon to catch domain words\n",
    "POS = {'good','great','excellent','engaging','clear','helpful','interactive','practical','relevant','well','like','liked','enjoyed','enjoy'}\n",
    "NEG = {'unclear','confusing','boring','late','delay','not','problem','difficult','lack','insufficient','poor','hard'}\n",
    "\n",
    "def lex_sentiment(text):\n",
    "    toks = text.split()\n",
    "    pos = sum(1 for t in toks if t in POS)\n",
    "    neg = sum(1 for t in toks if t in NEG)\n",
    "    if pos>neg:\n",
    "        return 'positive'\n",
    "    elif neg>pos:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "df['lex_sentiment'] = df['text'].apply(lex_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "855dead8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   topic_id                                           keywords  n_docs  \\\n",
      "0         0  practical, data, bi, business, real, lab, theo...      22   \n",
      "1         1  labs, time, content, unit, topics, work, lab, ...      27   \n",
      "2         2  slides, liked, labs, lecture, content, number,...      27   \n",
      "3         3  data, practical, labs, unit, tools, matter, en...      16   \n",
      "4         4  lab, assignments, content, work, group, practi...      23   \n",
      "5         5  topics, labs, think, end, topic, practical, un...      14   \n",
      "\n",
      "   vader_positive  vader_negative  vader_neutral  \n",
      "0              17               1              4  \n",
      "1              20               2              5  \n",
      "2              19               4              4  \n",
      "3              10               2              4  \n",
      "4              13               1              9  \n",
      "5              10               1              3  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# -------------- Step 5: Aggregate per-topic sentiments -------------\n",
    "topic_summary = []\n",
    "for t in range(n_topics):\n",
    "    docs = df[df['dominant_topic']==t]\n",
    "    n = len(docs)\n",
    "    if n==0:\n",
    "        continue\n",
    "    vader_counts = docs['vader_sentiment'].value_counts().to_dict()\n",
    "    lex_counts = docs['lex_sentiment'].value_counts().to_dict()\n",
    "    examples = docs['response'].head(5).tolist()\n",
    "    topic_summary.append({\n",
    "        'topic_id': t,\n",
    "        'keywords': topics[t],\n",
    "        'n_docs': n,\n",
    "        'vader_counts': vader_counts,\n",
    "        'lex_counts': lex_counts,\n",
    "        'examples': examples\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame([{\n",
    "    'topic_id': s['topic_id'],\n",
    "    'keywords': ', '.join(s['keywords']),\n",
    "    'n_docs': s['n_docs'],\n",
    "    'vader_positive': s['vader_counts'].get('positive',0),\n",
    "    'vader_negative': s['vader_counts'].get('negative',0),\n",
    "    'vader_neutral': s['vader_counts'].get('neutral',0)\n",
    "} for s in topic_summary])\n",
    "print(summary_df)\n",
    "\n",
    "# Save outputs and models for the demo app\n",
    "os.makedirs('output', exist_ok=True)\n",
    "joblib.dump(lda, 'output/lda_model.joblib')\n",
    "joblib.dump(vectorizer, 'output/vectorizer.joblib')\n",
    "df.to_csv('output/evaluations_with_topics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff005971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradio app code generated at 'output/gradio_app.py'\n"
     ]
    }
   ],
   "source": [
    "# -------------- Step 6: Produce a small Gradio demo file -------------\n",
    "gradio_code = f'''\n",
    "# gradio_app.py\n",
    "import re\n",
    "import joblib\n",
    "import gradio as gr\n",
    "\n",
    "# Load models\n",
    "lda = joblib.load(\"output/lda_model.joblib\")\n",
    "vectorizer = joblib.load(\"output/vectorizer.joblib\")\n",
    "topics = {topics}  # List of topic names\n",
    "\n",
    "POS = {sorted(list(POS))}  # Positive lexicon\n",
    "NEG = {sorted(list(NEG))}  # Negative lexicon\n",
    "\n",
    "def clean_text(s):\n",
    "    s = str(s).lower()\n",
    "    s = re.sub(r\"[^a-z0-9\\\\s]\", \" \", s)\n",
    "    s = re.sub(r\"\\\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def lex_sentiment(text):\n",
    "    toks = text.split()\n",
    "    score = sum(1 for t in toks if t in POS) - sum(1 for t in toks if t in NEG)\n",
    "    return score\n",
    "\n",
    "def predict(text):\n",
    "    text = clean_text(text)\n",
    "    bow = vectorizer.transform([text])\n",
    "    topic_id = lda.transform(bow)[0].argmax()\n",
    "    topic = topics[topic_id]  # Runtime lookup\n",
    "    sentiment_score = lex_sentiment(text)\n",
    "    return f\"Topic: {{topic}}, Sentiment: {{sentiment_score}}\"\n",
    "\n",
    "iface = gr.Interface(fn=predict, inputs=\"text\", outputs=\"text\")\n",
    "iface.launch()\n",
    "'''\n",
    "\n",
    "# Write to file\n",
    "with open('output/gradio_app.py','w', encoding='utf-8') as f:\n",
    "    f.write(gradio_code)\n",
    "\n",
    "print(\"Gradio app code generated at 'output/gradio_app.py'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d147ca63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained models\n",
    "joblib.dump(lda, 'lda_model.joblib')\n",
    "joblib.dump(vectorizer, 'vectorizer.joblib')\n",
    "print(\"Models saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_labels = {\n",
    "    0: \"Teaching Quality\",\n",
    "    1: \"Course Content & Structure\",\n",
    "    2: \"Workload & Assessments\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('course_evaluations.csv')\n",
    "df['clean'] = df['evaluation'].apply(preprocess)\n",
    "df['topic'] = lda.transform(vectorizer.transform(df['clean'])).argmax(axis=1)\n",
    "df['sentiment'] = df['evaluation'].apply(get_sentiment)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def predict(text):\n",
    "    clean = preprocess(text)\n",
    "    topic = lda.transform(vectorizer.transform([clean])).argmax()\n",
    "    sentiment = get_sentiment(text)\n",
    "    return topic_labels[topic], sentiment\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=gr.Textbox(lines=3, placeholder=\"Type a student's evaluation...\"),\n",
    "    outputs=[\"text\", \"text\"],\n",
    "    title=\"Course Evaluation NLP Analyzer\",\n",
    "    description=\"Predicts topic and sentiment from a student's course evaluation.\"\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of Results & Recommendations\n",
    "- **Teaching Quality** receives positive sentiments.\n",
    "- **Course Content & Structure** shows mixed feedback.\n",
    "- **Workload & Assessments** is the most negatively rated theme.\n",
    "\n",
    "### Recommendations\n",
    "- Standardize course structure to reduce confusion.\n",
    "- Balance workload across the semester.\n",
    "- Continue practical examples as they drive positive feedback."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
